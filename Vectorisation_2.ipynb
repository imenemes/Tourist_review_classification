{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imenemes/Tourist_review_classification/blob/main/Vectorisation_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Récupération des données**"
      ],
      "metadata": {
        "id": "P_r1kZ-dYz33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zvQuBn82dDx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCDFnjrGC46C",
        "outputId": "2b94cf3a-2dd0-47a2-8951-fa97c328c7ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_pickle('/content/drive/MyDrive/data_prep.txt')"
      ],
      "metadata": {
        "id": "_d74GA_UDGBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "sRqwNpZVDofN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "e1ad4df6-52f2-43a4-b22b-b684aa8de609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  Rating  Sentiment  \\\n",
              "0  nice hotel expensive parking got good deal sta...       4          1   \n",
              "1  ok nothing special charge diamond member hilto...       2          0   \n",
              "2  nice rooms not 4* experience hotel monaco seat...       3          0   \n",
              "3  unique, great stay, wonderful time hotel monac...       5          1   \n",
              "4  great stay great stay, went seahawk game aweso...       5          1   \n",
              "\n",
              "   char_count  Word_count  Average_Word_Length  \\\n",
              "0         593          87             6.816092   \n",
              "1        1689         250             6.756000   \n",
              "2        1427         217             6.576037   \n",
              "3         600          89             6.741573   \n",
              "4        1281         191             6.706806   \n",
              "\n",
              "                                               Clean  \\\n",
              "0  nice hotel expensive parking got good deal sta...   \n",
              "1  ok nothing special charge diamond member hilto...   \n",
              "2  nice rooms 4 experience hotel monaco seattle g...   \n",
              "3  unique great stay wonderful time hotel monaco ...   \n",
              "4  great stay great stay went seahawk game awesom...   \n",
              "\n",
              "                                        Review_lists  \n",
              "0  [nice, hotel, expensive, parking, got, good, d...  \n",
              "1  [ok, nothing, special, charge, diamond, member...  \n",
              "2  [nice, rooms, 4, experience, hotel, monaco, se...  \n",
              "3  [unique, great, stay, wonderful, time, hotel, ...  \n",
              "4  [great, stay, great, stay, went, seahawk, game...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36ddad38-d981-4ff9-8dfc-032291dcaf7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>char_count</th>\n",
              "      <th>Word_count</th>\n",
              "      <th>Average_Word_Length</th>\n",
              "      <th>Clean</th>\n",
              "      <th>Review_lists</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nice hotel expensive parking got good deal sta...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>593</td>\n",
              "      <td>87</td>\n",
              "      <td>6.816092</td>\n",
              "      <td>nice hotel expensive parking got good deal sta...</td>\n",
              "      <td>[nice, hotel, expensive, parking, got, good, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok nothing special charge diamond member hilto...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1689</td>\n",
              "      <td>250</td>\n",
              "      <td>6.756000</td>\n",
              "      <td>ok nothing special charge diamond member hilto...</td>\n",
              "      <td>[ok, nothing, special, charge, diamond, member...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1427</td>\n",
              "      <td>217</td>\n",
              "      <td>6.576037</td>\n",
              "      <td>nice rooms 4 experience hotel monaco seattle g...</td>\n",
              "      <td>[nice, rooms, 4, experience, hotel, monaco, se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>600</td>\n",
              "      <td>89</td>\n",
              "      <td>6.741573</td>\n",
              "      <td>unique great stay wonderful time hotel monaco ...</td>\n",
              "      <td>[unique, great, stay, wonderful, time, hotel, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great stay great stay, went seahawk game aweso...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1281</td>\n",
              "      <td>191</td>\n",
              "      <td>6.706806</td>\n",
              "      <td>great stay great stay went seahawk game awesom...</td>\n",
              "      <td>[great, stay, great, stay, went, seahawk, game...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36ddad38-d981-4ff9-8dfc-032291dcaf7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-36ddad38-d981-4ff9-8dfc-032291dcaf7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-36ddad38-d981-4ff9-8dfc-032291dcaf7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download(['punkt', 'wordnet', 'omw-1.4', 'stopwords'])"
      ],
      "metadata": {
        "id": "wGaTxGten9hS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c44318-3d0b-40c6-ce52-e51e317cb39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_review=df.Clean"
      ],
      "metadata": {
        "id": "40DtpaQSDw5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(['punkt', 'wordnet', 'omw-1.4', 'stopwords'])\n",
        "#text prerocessing\n",
        "def text_preprocess(text):\n",
        "    \"\"\"\n",
        "    Tokenize \n",
        "    Input: Raw text\n",
        "           \n",
        "    Output: Lemmatized texts\n",
        "    \"\"\"\n",
        "\n",
        "    text = re.sub(r'https?://\\S+', '', text) #remove http links\n",
        "    text = re.sub(r\"[^a-zA-Z]\", \" \", text) #remove punktuation and numbers\n",
        "    \n",
        "    tokens = word_tokenize(text) #tokenize to words\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = stopwords.words(\"english\")\n",
        "\n",
        "    clean_tokens = [lemmatizer.lemmatize(tok).lower().strip() for tok in tokens if tok not in stop_words] #lematization and stop words removal\n",
        "    \n",
        "    return ' '.join(clean_tokens)"
      ],
      "metadata": {
        "id": "PFgfUmmZnmqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fadfa98-8491-419b-f6eb-5fb190e82257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean = df['Review'].apply(text_preprocess)"
      ],
      "metadata": {
        "id": "jdC3vX14sIYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6 - **Vectorization** (featurization)"
      ],
      "metadata": {
        "id": "_Qhb5lol5tv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ],
      "metadata": {
        "id": "TfeHs0u3eqK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A- **Méthode BOW**"
      ],
      "metadata": {
        "id": "JmFgp4Hokl5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C'est le modèle de base utilisé dans le traitement du langage naturel.Il est appelé sac de mots parce que tout ordre des mots dans le document est écarté. Nous ne retrouverons que les informations sur la présence du mot ou non dans le jeu de données.\n",
        "\n",
        "Le modèle de sac de mots contient alors un ensemble de mots uniques dans l'ensemble des documents et les fréquences d'occurrence de chaque mot."
      ],
      "metadata": {
        "id": "WcsK3aOKY7N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# définir le tokenizer\n",
        "def tokenizer(text):\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "E0cvzKvyapM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_vectorizer = CountVectorizer(analyzer='word',lowercase=False)\n",
        "\n",
        "bow = bow_vectorizer.fit_transform(X_clean)"
      ],
      "metadata": {
        "id": "k9t563yMkstE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans notre cas chaque critique est un document séparé. Si nous faisons une liste de mots telle qu'un mot ne doit apparaître qu'une seule fois.\n",
        "\n"
      ],
      "metadata": {
        "id": "CpC0r7nkbCQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ainsi, chaque critique est converti en un vecteur de la même taille du vocabulaire , le nombre d'occurence du mot présent est mentionné dans l'index inital du mot , les mots non présents eux sont consigné avec 0.\n",
        "\n",
        "l'apporoche décrite plus haut est unigramme car nous ne considérons qu'un seul mot à la fois. De même, nous avons le bigramme (en utilisant deux mots à la fois), le trigramme (en utilisant trois mots à la fois), le ngramme (en utilisant n mots à la fois).\n",
        "\n",
        "Le processus de conversion du texte en vecteur est donc appelé vectorisation."
      ],
      "metadata": {
        "id": "5zzF6G91cKuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En utilisant la fonction CountVectorizer(), nous pouvons convertir un document texte en matrice de nombre de mots. La matrice produite ici est une matrice éparse. En utilisant CountVectorizer sur nos données ci-dessus, nous obtenons une matrice clairsemée de type numpy.int64.\n",
        "\n",
        "Après avoir appliqué la fonction CountVectorizer(), nous pouvons faire correspondre chaque mot à un idex comme le montre le tuple suivant."
      ],
      "metadata": {
        "id": "zXRZw05jdot-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tweet before vectorization: {}'.format(cleaned_review[18]))\n",
        "print('Tweet before vectorization: {}'.format(bow[18]))\n",
        "bow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovy49nIZaUIM",
        "outputId": "ef614c01-9d5e-4ca3-c949-dc109bb34423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet before vectorization: good choice hotel recommended sister great location room nice comfortable bed- quiet- staff helpful recommendations restaurants pike market 4 block walk stay\n",
            "Tweet before vectorization:   (0, 26539)\t1\n",
            "  (0, 19130)\t1\n",
            "  (0, 17171)\t1\n",
            "  (0, 37568)\t1\n",
            "  (0, 33757)\t1\n",
            "  (0, 3990)\t1\n",
            "  (0, 8360)\t1\n",
            "  (0, 23140)\t1\n",
            "  (0, 17467)\t1\n",
            "  (0, 37335)\t1\n",
            "  (0, 18488)\t1\n",
            "  (0, 4717)\t1\n",
            "  (0, 7492)\t1\n",
            "  (0, 43088)\t1\n",
            "  (0, 29488)\t1\n",
            "  (0, 31400)\t1\n",
            "  (0, 33049)\t1\n",
            "  (0, 24219)\t1\n",
            "  (0, 32079)\t1\n",
            "  (0, 35972)\t1\n",
            "  (0, 32076)\t1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20491, 44754)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est également important de noter ici que, puisqu'il y a une énorme liste de mots dans un ensemble de données, tous les messages ne contiendront pas tous les mots. Ainsi, la plupart des places dans les vecteurs seront nulles. Par conséquent, la façon dont ces messages sont stockés dans le modèle de sac de mots est en utilisant une matrice éparse."
      ],
      "metadata": {
        "id": "Yw0tEijKqdVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Méthode pour récupérer les mots les plus courant dans le document"
      ],
      "metadata": {
        "id": "_nB-B18qff1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mots les plus courants et leur nombre respectif\n",
        "def get_most_freq_words(str, n=None):\n",
        "    vect = CountVectorizer().fit(cleaned_review)\n",
        "    bag_of_words = vect.transform(cleaned_review)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
        "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
        "    return freq[:n]\n",
        "  \n",
        "get_most_freq_words([ word for tweet in cleaned_review for word in tweet],20)"
      ],
      "metadata": {
        "id": "4rItQIlB4QRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a5cddc-5d3e-4f37-ffc0-d155ef11fb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('hotel', 48959),\n",
              " ('room', 34588),\n",
              " ('great', 21127),\n",
              " ('nt', 18989),\n",
              " ('good', 17047),\n",
              " ('staff', 16223),\n",
              " ('stay', 15171),\n",
              " ('nice', 12427),\n",
              " ('rooms', 12047),\n",
              " ('location', 11064),\n",
              " ('stayed', 10466),\n",
              " ('service', 10045),\n",
              " ('time', 9890),\n",
              " ('beach', 9613),\n",
              " ('night', 9589),\n",
              " ('day', 9511),\n",
              " ('clean', 9378),\n",
              " ('breakfast', 9285),\n",
              " ('food', 9018),\n",
              " ('like', 8197)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "J'essaie ici de jouer avec min_df et max_df de countvectorizer , et ça n'a pas l'air de marcher , car les tweets ont bien été nettoyé, de plus cela témoingne d'une grande diversité des mots au sein de notre corpus"
      ],
      "metadata": {
        "id": "iCGLJtfUhdAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mots les plus courants et leur nombre respectif\n",
        "def get_most_freq_words(str, n=None):\n",
        "    vect = CountVectorizer(max_df=0.3, min_df=5).fit(cleaned_review)\n",
        "    bag_of_words = vect.transform(cleaned_review)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
        "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
        "    return freq[:n]\n",
        "  \n",
        "get_most_freq_words([ word for tweet in cleaned_review for word in tweet],20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8u0wCHzgdQ1",
        "outputId": "033212f3-1101-4ccb-da20-3114cc8478e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('beach', 9613),\n",
              " ('day', 9511),\n",
              " ('food', 9018),\n",
              " ('like', 8197),\n",
              " ('resort', 7948),\n",
              " ('really', 7766),\n",
              " ('place', 7693),\n",
              " ('pool', 7203),\n",
              " ('people', 6773),\n",
              " ('friendly', 6751),\n",
              " ('small', 6543),\n",
              " ('little', 6244),\n",
              " ('got', 6186),\n",
              " ('walk', 6181),\n",
              " ('excellent', 6025),\n",
              " ('area', 5939),\n",
              " ('best', 5682),\n",
              " ('helpful', 5461),\n",
              " ('bar', 5311),\n",
              " ('restaurant', 5174)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On constate ici que les mots les plus courants avec BOW sont des verbes non conjugés tels que : être, faire, avoir, etc. "
      ],
      "metadata": {
        "id": "7DTqIxmd5Ig7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B- **Méthode TFIDF**"
      ],
      "metadata": {
        "id": "hGqwHTyn58F0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF** est l'abréviation de Term Frequency-Inverse Document Frequency, qui indique l'importance d'un mot dans un corpus ou un ensemble de données. TF-IDF contient deux concepts : la fréquence des mots (TF) et la fréquence inverse des documents (IDF).\n",
        "\n",
        "**TF** :La fréquence d'apparition du mot dans le document ou le corpus.\n",
        "\n",
        "**IDF**: La fréquence inverse des documents est un autre concept utilisé pour déterminer l'importance d'un mot. Elle est basée sur le fait que les mots moins fréquents sont plus informatifs et plus importants.\n",
        "\n",
        "**TF-IDF** réduit essentiellement les valeurs des mots communs qui sont utilisés dans différents documents. "
      ],
      "metadata": {
        "id": "jhWn3jnhgw0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from numpy.lib.function_base import vectorize\n",
        "#utiliser la méthode de Tfidfvectorizer avec:\n",
        "\"\"\" - les stopsword français importés depuis spacy\n",
        "    - le tokenizer définis plus haut\"\"\"\n",
        "vectorizer = TfidfVectorizer(lowercase=False)\n",
        "print('Tweet before vectorization: {}'.format(cleaned_review[18]))"
      ],
      "metadata": {
        "id": "smsdUUntlBiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d4f724-0951-400f-b3d5-09777aff7c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet before vectorization: good choice hotel recommended sister great location room nice comfortable bed- quiet- staff helpful recommendations restaurants pike market 4 block walk stay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer les tweets en vecteurs\n",
        "# qui prend en argument les vecteurs de mots de l'ensemble des tweets nettoyés précédemment \n",
        "X = vectorizer.fit_transform(cleaned_review)\n",
        "print('Tweet after vectorization: \\n{}'.format(X[18]))\n",
        "\n",
        "#print ((X.todense()))"
      ],
      "metadata": {
        "id": "gidfHw67lY61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333e4728-572b-48f8-d43b-18a61c0d6e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet after vectorization: \n",
            "  (0, 55128)\t0.3477573340444639\n",
            "  (0, 61406)\t0.3586809594082026\n",
            "  (0, 55142)\t0.28066881222309187\n",
            "  (0, 56632)\t0.18006391081601178\n",
            "  (0, 42453)\t0.286763494315192\n",
            "  (0, 54113)\t0.21038481193881264\n",
            "  (0, 50938)\t0.39599193384472753\n",
            "  (0, 73111)\t0.16674983356160583\n",
            "  (0, 15626)\t0.24404611191366193\n",
            "  (0, 11275)\t0.2745097997218386\n",
            "  (0, 33331)\t0.16179896732735982\n",
            "  (0, 63581)\t0.10621002493668845\n",
            "  (0, 31681)\t0.1092114209944032\n",
            "  (0, 40760)\t0.1293449433369706\n",
            "  (0, 17093)\t0.1804144446370512\n",
            "  (0, 10053)\t0.18106777467027252\n",
            "  (0, 57715)\t0.09270446205216046\n",
            "  (0, 64105)\t0.1151514282470967\n",
            "  (0, 31193)\t0.12069453278999343\n",
            "  (0, 34479)\t0.08275821323841055\n",
            "  (0, 46050)\t0.13589993300010456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idf=vectorizer.idf_"
      ],
      "metadata": {
        "id": "sQhXl5-rqQcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2vec :**Il s'agit d'une technique d'apprentissage profond avec un réseau neuronal à deux couches. Word2vec prend l'entrée des données (dans ce cas nous utilisons nos propres données) et la convertit en espace vectoriel tel que les mots ayant une signification similaire soient regroupés ensemble et la distance entre ces mots soit similaire aussi."
      ],
      "metadata": {
        "id": "AIKV1lKSjyJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "D- **Méthode W2Vec**"
      ],
      "metadata": {
        "id": "AUvbGV6_NROn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=list(cleaned_review)\n",
        "cleaned_tweet_list= [line.split() for line in data]"
      ],
      "metadata": {
        "id": "4xZaDXMLE464"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "\n",
        "#tokenized_tweet = s.apply(lambda x: x.split()) # tokenizing \n",
        "\n",
        "model_w2v = gensim.models.Word2Vec(\n",
        "            cleaned_tweet_list,\n",
        "            size=200, # desired no. of features/independent variables\n",
        "            window=5, # context window size\n",
        "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
        "            sg = 1, # 1 for skip-gram model\n",
        "            hs = 0,\n",
        "            negative = 10, # for negative sampling\n",
        "            workers= 32, # no.of cores\n",
        "            seed = 34\n",
        ") \n"
      ],
      "metadata": {
        "id": "txJlUHR5NQma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_w2v)"
      ],
      "metadata": {
        "id": "wXGVsdYPs_c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001ec1c4-d9fc-4088-d011-0729562833d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=31077, size=200, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(model_w2v.wv.vocab)"
      ],
      "metadata": {
        "id": "gF1ZmwWRtaor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nombre de mots dans le vocabulaire \n",
        "\n",
        "vocab_len = len(model_w2v.wv.vocab)\n",
        "print(vocab_len)"
      ],
      "metadata": {
        "id": "M1vF2EC6R4qR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b35b722-390e-44b8-b724-19cf25170e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v['hotel']"
      ],
      "metadata": {
        "id": "0AZVM5rFPjNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6eb985-84fc-4384-bafb-45c64ccb7605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-e0d6e765d2ab>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  model_w2v['hotel']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.36954412e-01, -7.10269883e-02,  2.66110748e-01,  3.36379297e-02,\n",
              "       -1.04235001e-01, -5.26341088e-02, -3.30351979e-01, -3.54220510e-01,\n",
              "        2.79880017e-02,  4.61494848e-02,  1.93942949e-01,  1.19290665e-01,\n",
              "       -2.19330117e-01, -3.23864400e-01, -5.41423373e-02, -5.39687127e-02,\n",
              "       -1.41990855e-01,  1.85684368e-01, -2.79592220e-02,  1.00220583e-01,\n",
              "        3.01528752e-01, -1.63515270e-01, -5.99567443e-02,  3.07009816e-01,\n",
              "        8.05257559e-02, -4.53346148e-02, -1.57717839e-01, -7.98496604e-02,\n",
              "        1.03683144e-01,  9.82159972e-02,  1.68846861e-01, -2.73027301e-01,\n",
              "       -8.51391330e-02, -1.51463924e-02, -5.38607091e-02,  3.22468430e-02,\n",
              "       -2.18374714e-01, -1.39652655e-01, -1.53371155e-01, -1.88670382e-01,\n",
              "       -1.99044384e-02, -1.49855852e-01,  1.15652107e-01,  7.68602565e-02,\n",
              "        1.61825165e-01,  1.55527472e-01,  2.03074336e-01,  2.08540577e-02,\n",
              "        1.04529060e-01,  7.63675645e-02, -6.38163835e-02, -1.15003757e-01,\n",
              "        1.34626940e-01,  3.65731381e-02, -1.09920673e-01, -2.96092767e-04,\n",
              "        1.77769568e-02,  1.27865300e-01,  6.11531213e-02, -1.63056687e-01,\n",
              "        1.01226173e-01,  1.43103480e-01, -4.38378870e-01, -2.30242208e-01,\n",
              "       -2.56610036e-01, -6.53135851e-02,  1.27432644e-02, -1.85253620e-02,\n",
              "        1.82578817e-01, -8.55273679e-02,  1.45519361e-01,  1.30741939e-01,\n",
              "       -2.18575388e-01, -2.99237333e-02, -1.44357570e-02, -1.18838884e-01,\n",
              "       -1.13439690e-02, -2.71086693e-01,  2.46747836e-01, -6.48701862e-02,\n",
              "        2.07682937e-01, -1.94212481e-01, -5.25947958e-02, -1.14459068e-01,\n",
              "        4.55465503e-02, -4.54449579e-02, -2.14278638e-01, -7.60505348e-02,\n",
              "       -1.49874762e-01, -1.59787595e-01,  1.09924756e-01, -9.95350406e-02,\n",
              "       -2.10023627e-01, -1.55056894e-01,  3.38923872e-01, -3.02120391e-02,\n",
              "       -3.79905440e-02,  1.06884912e-01,  1.73243061e-01,  6.85512554e-03,\n",
              "        2.81449467e-01, -1.82438910e-01,  1.11146450e-01,  1.70417622e-01,\n",
              "        1.83368862e-01, -6.57528359e-03, -2.84306183e-02, -8.04163963e-02,\n",
              "        1.88348725e-01, -1.35560423e-01, -1.13936640e-01,  6.08957969e-02,\n",
              "        2.68797092e-02, -1.07919358e-01, -1.30810216e-01, -1.91175509e-02,\n",
              "       -5.33988476e-02, -1.65055722e-01,  1.05370460e-02, -4.80079293e-01,\n",
              "       -3.11203040e-02,  2.71301717e-01,  4.95841168e-02,  2.16401622e-01,\n",
              "       -3.08931898e-02,  1.89464837e-01, -3.10645074e-01,  3.49612683e-02,\n",
              "        3.57414514e-01,  1.79541588e-01,  1.27357647e-01,  1.42832145e-01,\n",
              "       -5.95537663e-01,  1.42387568e-03, -8.92659873e-02, -4.16678526e-02,\n",
              "        2.79797494e-01, -3.46221030e-01,  2.65574396e-01, -7.78519362e-02,\n",
              "       -4.62811776e-02, -3.89032781e-01, -3.30514669e-01, -1.57148585e-01,\n",
              "        1.23657808e-02, -4.58775833e-02,  1.89232692e-01, -2.42431581e-01,\n",
              "        1.65007010e-01, -2.70914465e-01,  2.27061495e-01,  1.10422000e-02,\n",
              "        1.36541128e-01, -1.44285411e-01,  1.22372188e-01, -3.34463745e-01,\n",
              "       -2.28419676e-01, -8.67079347e-02,  3.06066602e-01, -4.62067991e-01,\n",
              "       -1.68550983e-01,  9.10048261e-02, -8.74614343e-02,  4.13046665e-02,\n",
              "       -4.10425179e-02,  3.62170666e-01, -1.31213829e-01,  9.92687345e-02,\n",
              "        9.95126665e-02, -1.90010756e-01, -1.41425431e-01,  1.01112621e-02,\n",
              "        2.34136552e-01, -9.42099690e-02,  2.76016314e-02, -3.29274893e-01,\n",
              "       -1.58094421e-01, -9.26075280e-02,  2.07946375e-02,  1.36959195e-01,\n",
              "       -4.67934608e-02, -4.52810347e-01,  1.80974543e-01, -1.21857435e-01,\n",
              "        1.82191640e-01, -4.59997267e-01,  2.09054276e-01,  1.04103535e-01,\n",
              "        1.00353071e-02, -1.78420484e-01, -3.58701684e-02,  5.03343940e-02,\n",
              "        1.46783933e-01,  1.22038126e-01,  1.52400890e-02,  6.20501563e-02,\n",
              "        1.92345485e-01,  2.47663394e-01, -1.81171119e-01, -9.02881548e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On voit que notre modèle utilisant notre échantillon de 5000 mots n'est pas totalement abouti"
      ],
      "metadata": {
        "id": "Sv4xT4iFmDcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_w2v.wv.most_similar(positive=\"holiday\")"
      ],
      "metadata": {
        "id": "E1E-ehOjOpip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0835a4f3-dffc-4c5a-a5ea-003c35791eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('vacation', 0.6271520853042603),\n",
              " ('expresses', 0.6188887357711792),\n",
              " ('holidays', 0.6116487383842468),\n",
              " ('chime', 0.6109617352485657),\n",
              " ('drury', 0.6094635128974915),\n",
              " ('brentwood', 0.598535418510437),\n",
              " ('sonesta', 0.5932378768920898),\n",
              " ('hols', 0.5908829569816589),\n",
              " ('depressed', 0.5906240940093994),\n",
              " ('experiance', 0.5899096727371216)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}